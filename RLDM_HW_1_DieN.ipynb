{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reinforcement Learning and Decision Making &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Homework #1\n",
    "\n",
    "# &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Planning in MDPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "You are given an $N$-sided die, along with a corresponding Boolean mask\n",
    "vector, `is_bad_side` (i.e., a vector of ones and zeros). You can assume\n",
    "that $1<N\\leq30$, and the vector `is_bad_side` is also of size $N$ and\n",
    "$1$ indexed (since there is no $0$ side on the die). The game of DieN is\n",
    "played as follows:\n",
    "\n",
    "1.  You start with $0$ dollars.\n",
    "\n",
    "2.  At any time you have the option to roll the die or to quit the game.\n",
    "\n",
    "    1.  **ROLL**:\n",
    "\n",
    "        1.  If you roll a number not in `is_bad_side`, you receive that\n",
    "            many dollars (e.g., if you roll the number $2$ and $2$ is\n",
    "            not a bad side -- meaning the second element of the vector\n",
    "            `is_bad_side` is $0$, then you receive $2$ dollars). Repeat\n",
    "            step 2.\n",
    "\n",
    "        2.  If you roll a number in `is_bad_side`, then you lose all the\n",
    "            money obtained in previous rolls and the game ends.\n",
    "\n",
    "    2.  **QUIT**:\n",
    "\n",
    "        1.  You keep all the money gained from previous rolls and the\n",
    "            game ends.\n",
    "\n",
    "## Procedure\n",
    "\n",
    "-   You will implement your solution using the `solve()` method\n",
    "    in the code below.\n",
    "    \n",
    "-   Your return value should be the number of dollars you expect to\n",
    "    win for a specific value of `is_bad_side`, if you follow an\n",
    "    optimal policy. That is, what is the value of the optimal\n",
    "    state-value function for the initial state of the game (starting\n",
    "    with $0$ dollars)? Your answer must be correct to $3$ decimal\n",
    "    places, truncated (e.g., 3.14159265 becomes 3.141).\n",
    "\n",
    "-   To solve this problem, you will need to determine an optimal policy\n",
    "    for the game of DieN, given a particular configuration of the die.\n",
    "    As you will see, the action that is optimal will depend on your\n",
    "    current bankroll (i.e., how much money you've won so far).\n",
    "\n",
    "-   You can try solving this problem by creating an MDP of the game\n",
    "    (states, actions, transition function, reward function, and assume a\n",
    "    discount rate of $\\gamma=1$) and then calculating the optimal\n",
    "    state-value function.\n",
    "\n",
    "## Resources\n",
    "\n",
    "The concepts explored in this homework are covered by:\n",
    "\n",
    "-   Lecture Lesson 1: Smoov & Curly's Bogus Journey\n",
    "\n",
    "-   Chapter 3 (3.6 Optimal Policies and Optimal Value Functions) and\n",
    "    Chapter 4 (4.3-4.4 Policy Iteration, Value Iteration) of\n",
    "    http://incompleteideas.net/book/the-book-2nd.html\n",
    "\n",
    "-   Chapters 1-2 of 'Algorithms for Sequential Decision Making', M.\n",
    "    Littman, 1996\n",
    "\n",
    "## Submission\n",
    "\n",
    "-   The due date is indicated on the Canvas page for this assignment.\n",
    "    Make sure you have your timezone in Canvas set to ensure the\n",
    "    deadline is accurate.\n",
    "\n",
    "-   Submit your finished notebook on Gradescope. Your grade is based on\n",
    "    a set of hidden test cases. You will have unlimited submissions -\n",
    "    only the last score is kept.\n",
    "\n",
    "-   Use the template below to implement your code. We have also provided\n",
    "    some test cases for you. If your code passes the given test cases,\n",
    "    it will run (though possibly not pass all the tests) on Gradescope.\n",
    "\n",
    "-   Gradescope is using *python 3.6.x* and *numpy==1.18.0*, and you can\n",
    "    use any core library (i.e., anything in the Python standard library).\n",
    "    No other library can be used.  Also, make sure the name of your\n",
    "    notebook matches the name of the provided notebook.  Gradescope times\n",
    "    out after 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# DO NOT REMOVE\n",
    "# Versions\n",
    "# numpy==1.18.0\n",
    "################\n",
    "import numpy as np\n",
    "class MDPAgent(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_environment(self, face_count, state_count, good_sides):\n",
    "        T = np.zeros((2, state_count, state_count))\n",
    "        R = np.zeros((2, state_count, state_count))\n",
    "        \n",
    "        possible_bankroll_state = good_sides.copy()\n",
    "        possible_bankroll_state.insert(0,0)\n",
    "        \n",
    "        T_roll = np.zeros((state_count, state_count))\n",
    "        T_quit = np.zeros((state_count, state_count))\n",
    "        R_roll = np.zeros((state_count, state_count))\n",
    "        R_quit = np.zeros((state_count, state_count))\n",
    "        \n",
    "        # loop through all state values and set T/R       \n",
    "        for state_val in range(0, state_count):\n",
    "            T_roll_val = np.zeros(state_count)\n",
    "            R_roll_val = np.zeros(state_count)\n",
    "            # if the state value is in the array of possible bankroll states, we need to update \n",
    "            if state_val in possible_bankroll_state:\n",
    "                p_t = 1\n",
    "                # go through each possible roll\n",
    "                for side in good_sides:\n",
    "                    # generate a new state by adding them and if it's within the cap\n",
    "                    new_state = side + state_val\n",
    "                    if new_state < state_count - 1:\n",
    "                        # update the transition probability for that new state                        \n",
    "                        p_t = p_t - (1 / face_count)\n",
    "                        T_roll_val[new_state] = 1 / face_count\n",
    "                        # update the reward for that new state \n",
    "                        R_roll_val[new_state] = side\n",
    "                        # update the state to include new bankroll val\n",
    "                        if new_state not in possible_bankroll_state:\n",
    "                            possible_bankroll_state.append(new_state)\n",
    "                T_roll_val[state_count - 1] = p_t\n",
    "                R_roll_val[state_count - 1] = -state_val\n",
    "            \n",
    "            T_roll[state_val] = T_roll_val\n",
    "            R_roll[state_val] = R_roll_val\n",
    "            \n",
    "        T = [T_roll, T_quit]\n",
    "        R = [R_roll, R_quit]\n",
    "        return T, R\n",
    "    \n",
    "    def determine_initial_state_value(self, T, probabilities, state_count):\n",
    "        values = np.empty(state_count)\n",
    "        policy = np.empty((2, state_count))\n",
    "        i = 0\n",
    "        max_iter = 1000000000\n",
    "        while True:\n",
    "            i += 1\n",
    "            prev_vals = values.copy()\n",
    "            # calculate policy for roll, quit and choose the action with the highest value \n",
    "            for i, _ in enumerate(probabilities):\n",
    "                policy[i] = probabilities[i] + T[i].dot(values)\n",
    "    \n",
    "            values = np.max(policy,axis=0)\n",
    "            comparison = values - prev_vals\n",
    "            diff =  np.max(comparison) - np.min(comparison)\n",
    "            if (diff < 0.0000001) or (i > max_iter):\n",
    "                return np.max(values)     \n",
    "\n",
    "    def solve(self, is_bad_side):\n",
    "        \"\"\"Implement the agent\"\"\"\n",
    "        good_sides = []\n",
    "        for i, bad_side in enumerate(is_bad_side):\n",
    "            if not bad_side:\n",
    "                good_sides.append(i + 1)\n",
    "        # set large enough bank roll possibility range to pass tests\n",
    "        state_count = 4 * len(is_bad_side)\n",
    "        \n",
    "        T, R = self.set_environment(len(is_bad_side), state_count, good_sides)\n",
    "        # multiply the matricies and take the sum\n",
    "        r_t_probabilities = np.zeros([2, state_count])\n",
    "        r_t_probabilities[0] = np.sum((R[0] * T[0]),axis=1)\n",
    "        r_t_probabilities[1] = np.sum((R[1] * T[1]),axis=1)\n",
    "        # define a policy for each state, roll or quit\n",
    "        # print(r_t_probabilities)\n",
    "        initial_value = self.determine_initial_state_value(T, r_t_probabilities, state_count)\n",
    "        # print(initial_value)\n",
    "        return initial_value\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cases\n",
    "\n",
    "We have provided some test cases for you to help verify your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_case_1 (__main__.TestDieNNotebook) ... ok\n",
      "test_case_2 (__main__.TestDieNNotebook) ... ok\n",
      "test_case_3 (__main__.TestDieNNotebook) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.009s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fa37cab5460>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## DO NOT MODIFY THIS CODE.  This code will ensure that your submission\n",
    "## will work proberly with the autograder\n",
    "\n",
    "import unittest\n",
    "\n",
    "class TestDieNNotebook(unittest.TestCase):\n",
    "    def test_case_1(self):\n",
    "        agent = MDPAgent()\n",
    "        np.testing.assert_almost_equal(\n",
    "            agent.solve(is_bad_side=[1, 1, 1, 0, 0, 0]),\n",
    "            2.583,\n",
    "            decimal=3\n",
    "        )\n",
    "        \n",
    "    def test_case_2(self):\n",
    "        agent = MDPAgent()\n",
    "        np.testing.assert_almost_equal(\n",
    "            agent.solve(\n",
    "                is_bad_side=[1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0]\n",
    "            ),\n",
    "            7.379,\n",
    "            decimal=3\n",
    "        )\n",
    "        \n",
    "    def test_case_3(self):\n",
    "        agent = MDPAgent()\n",
    "\n",
    "        np.testing.assert_almost_equal(\n",
    "            agent.solve(\n",
    "                is_bad_side=[1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
    "            ),\n",
    "            6.314,\n",
    "            decimal=3\n",
    "        )\n",
    "\n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}